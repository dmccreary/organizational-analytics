# Quiz: Employee Event Streams

Test your understanding of organizational data sources, event logs, normalization, enrichment, and business process mining with these review questions.

---

#### 1. What is an employee event stream?

<div class="upper-alpha" markdown>
1. A chronological sequence of discrete, timestamped actions generated by an employee using organizational tools
2. A static spreadsheet listing employee names and job titles
3. A database table containing annual performance review scores
4. A printed report summarizing quarterly headcount changes
</div>

??? question "Show Answer"
    The correct answer is **A**. An employee event stream is a chronological sequence of discrete actions or interactions generated as an employee uses organizational tools and systems. Each event captures a single moment -- a message sent, a file opened, a badge swiped -- along with metadata describing the who, what, when, and where. Event streams are temporal, continuous, high-volume, multi-source, and relational, distinguishing them from static HR records like spreadsheets or annual reports.

    **Concept Tested:** Employee Event Streams

---

#### 2. Which six fields are considered the minimum required components of a well-formed event log entry?

<div class="upper-alpha" markdown>
1. Name, salary, department, title, manager, and location
2. Timestamp, actor, action, target, source system, and event ID
3. Username, password, IP address, session ID, browser type, and cookie
4. Revenue, cost, profit, margin, quarter, and fiscal year
</div>

??? question "Show Answer"
    The correct answer is **B**. Every well-formed event log entry must contain at minimum: a timestamp (when the event occurred), an actor (who performed the action), an action (what happened), a target (what or who the action was directed at), a source system (which tool generated the event), and an event ID (a unique identifier for deduplication and tracing). Additional context fields like IP addresses, device identifiers, and content length are optional metadata that add analytical value.

    **Concept Tested:** Event Logs

---

#### 3. Why is converting all event timestamps to UTC in ISO 8601 format important for organizational analytics?

<div class="upper-alpha" markdown>
1. UTC formatting makes events load faster into relational databases
2. ISO 8601 is the only format that graph databases can parse
3. Universal timestamps ensure accurate chronological ordering when combining events from systems in different time zones
4. UTC conversion automatically removes duplicate events from the stream
</div>

??? question "Show Answer"
    The correct answer is **C**. When event data arrives from multiple systems, each may record time differently -- email servers in UTC, chat platforms in local timezone, badge systems in building timezone. Without normalization to a single standard, you cannot reliably determine event sequence. Converting everything to UTC in ISO 8601 format (e.g., 2026-03-15T14:32:07Z) ensures that chronological sorting and time-gap calculations are accurate across all sources. This is essential because in organizational analytics, sequence matters enormously.

    **Concept Tested:** Universal Timestamps

---

#### 4. What type of data do email event streams capture for organizational analytics?

<div class="upper-alpha" markdown>
1. The full text content of every email message and all attachments
2. Only the total count of emails sent per department per quarter
3. Metadata such as sender, recipients, timestamps, and thread IDs -- not message content
4. Employee performance ratings derived from email sentiment analysis
</div>

??? question "Show Answer"
    The correct answer is **C**. Email event streams for organizational analytics work with metadata, not message content. The metadata includes sender, recipients, CC/BCC lists, timestamps, subject line hashes, attachment counts, thread IDs, and message size. This metadata alone reveals communication patterns, network structure, cross-departmental bridges, and response patterns. Subject hashing preserves thread detection without storing sensitive content. This metadata-over-content approach is a key privacy-preserving technique.

    **Concept Tested:** Email Event Streams

---

#### 5. How do chat event streams differ from email event streams in their analytical value?

<div class="upper-alpha" markdown>
1. Chat streams are always more private and cannot be analyzed
2. Chat streams capture faster-paced, informal collaboration including channel messages, reactions, and mentions
3. Chat streams only record one-to-one conversations and never group interactions
4. Chat streams do not include timestamps so they cannot be chronologically ordered
</div>

??? question "Show Answer"
    The correct answer is **B**. Chat event streams from platforms like Slack and Microsoft Teams capture interactions that are typically faster-paced and more informal than email. They include direct messages, channel messages, emoji reactions, thread replies, mentions, and file shares. Their analytical value lies in revealing spontaneous, day-to-day collaboration patterns that email misses. An employee might send five emails but exchange fifty chat messages in a day. Channel membership data also reveals organizational reach beyond individual message analysis.

    **Concept Tested:** Chat Event Streams

---

#### 6. What is the primary goal of event normalization?

<div class="upper-alpha" markdown>
1. Deleting all events older than thirty days to reduce storage costs
2. Encrypting event data so it cannot be read by unauthorized users
3. Transforming raw events from diverse sources into a consistent, standardized format with common field names and controlled vocabulary
4. Converting graph database records back into relational table rows
</div>

??? question "Show Answer"
    The correct answer is **C**. Event normalization transforms raw event data from diverse sources into a consistent format so that all events speak the same language regardless of origin. This involves field mapping (standardizing field names like "sender," "from," and "originator" all becoming "actor"), timestamp conversion to UTC, creating a controlled action vocabulary (Slack's "message_posted" and Teams' "chatMessageSent" both become "CHAT_SEND"), identity resolution, and schema alignment. Without normalization, combining events from different systems is unreliable.

    **Concept Tested:** Event Normalization

---

#### 7. Which of the following is an example of event enrichment rather than event normalization?

<div class="upper-alpha" markdown>
1. Converting a Unix timestamp to ISO 8601 UTC format
2. Mapping a Slack user ID to a canonical employee ID
3. Adding the actor's department, tenure, and whether the communication is cross-departmental
4. Renaming a field from "sender" to "actor" for consistency
</div>

??? question "Show Answer"
    The correct answer is **C**. Event enrichment augments normalized events with contextual information drawn from other data sources. Adding the actor's department, tenure in days, and a cross-departmental flag are enrichment operations because they bring in external organizational context that was not present in the original event. In contrast, timestamp conversion, identity resolution, and field renaming are normalization operations that standardize the event's own data without adding new external context.

    **Concept Tested:** Event Enrichment

---

#### 8. What three fields are the fundamental inputs required for process discovery algorithms?

<div class="upper-alpha" markdown>
1. Employee name, salary, and department
2. Source system, IP address, and browser type
3. Graph node ID, edge type, and weight
4. Case ID, activity name, and timestamp
</div>

??? question "Show Answer"
    The correct answer is **D**. Process discovery algorithms require three essential fields in the event log: a case ID (which process instance the event belongs to, such as a specific purchase order or onboarding), an activity name (what happened, such as "Submit Request" or "Manager Approval"), and a timestamp (when it happened). From these three fields, algorithms like alpha mining, heuristic mining, and inductive mining can reconstruct the typical process flow, identify variations, detect bottlenecks, and surface exceptional paths.

    **Concept Tested:** Process Discovery

---

#### 9. In process conformance analysis, what does it mean when an activity is classified as an "inserted activity"?

<div class="upper-alpha" markdown>
1. An activity from the reference model that was performed by the wrong person
2. An activity that occurred in practice but does not exist in the reference process model
3. An activity that was performed in the correct sequence according to the documented process
4. An activity that was skipped during process execution
</div>

??? question "Show Answer"
    The correct answer is **B**. Process conformance analysis compares actual process execution against a reference model and identifies four types of deviations. An inserted activity is a step that occurred in practice but is not part of the documented reference model -- for example, an unofficial peer review that teams added on their own. Importantly, inserted activities are not always problems; they may represent positive deviations that improve outcomes and should potentially be formalized into the official process.

    **Concept Tested:** Process Conformance

---

#### 10. An analyst notices that meeting patterns show two teams never share calendar events, yet they exchange frequent emails and have active cross-team chat channels. What does this combination of event streams reveal?

<div class="upper-alpha" markdown>
1. The calendar system has a data extraction error and needs debugging
2. Both teams should be immediately merged into a single department
3. The teams have strong informal communication ties despite no formal meeting structure connecting them
4. Email and chat data should be deleted since it contradicts the calendar data
</div>

??? question "Show Answer"
    The correct answer is **C**. Combining multiple event streams reveals organizational dynamics that no single source can expose. When two teams lack shared calendar events but exchange frequent emails and active cross-team chat messages, it indicates strong informal collaboration without formal meeting structures. This insight -- only visible by cross-referencing calendar, email, and chat streams -- might suggest the teams would benefit from scheduled cross-functional meetings to support the collaboration already occurring organically.

    **Concept Tested:** Meeting Patterns

---
